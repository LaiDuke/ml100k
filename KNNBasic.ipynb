{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import heapq\n",
    "import time\n",
    "import pandas as pd\n",
    "from surprise import *\n",
    "from surprise import Reader, accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SymmetricAlgo(AlgoBase):\n",
    "    def __init__(self, sim_options={}, verbose=True, **kwargs):\n",
    "        AlgoBase.__init__(self, sim_options=sim_options, **kwargs)\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        \n",
    "        \n",
    "    def fit(self, trainset):\n",
    "        AlgoBase.fit(self, trainset)\n",
    "        ub = self.sim_options['user_based']\n",
    "        self.n_x = self.trainset.n_users if ub else self.trainset.n_items\n",
    "        self.n_y = self.trainset.n_items if ub else self.trainset.n_users\n",
    "        self.xr = self.trainset.ur if ub else self.trainset.ir\n",
    "        self.yr = self.trainset.ir if ub else self.trainset.ur\n",
    "        return self\n",
    "\n",
    "    \n",
    "    \n",
    "    def switch(self, u_stuff, i_stuff):\n",
    "        if self.sim_options['user_based']:\n",
    "            return u_stuff, i_stuff\n",
    "        else:\n",
    "            return i_stuff, u_stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyOwnAlgorithm(SymmetricAlgo):\n",
    "    def __init__(self, k=40, min_k=1, sim_options={}, verbose=True, **kwargs):\n",
    "        SymmetricAlgo.__init__(self, sim_options=sim_options, verbose=verbose,**kwargs)\n",
    "        self.k = k\n",
    "        self.min_k = min_k\n",
    "    \n",
    "        \n",
    "    def fit(self, trainset):\n",
    "        SymmetricAlgo.fit(self, trainset)\n",
    "        self.sim = self.compute_similarities()\n",
    "        return self\n",
    "\n",
    "    \n",
    "    def estimate(self, u, i):\n",
    "        if not (self.trainset.knows_user(u) and self.trainset.knows_item(i)):\n",
    "            raise PredictionImpossible('user and/or item is unkown.')\n",
    "        x, y = self.switch(u, i)\n",
    "        neighbors = [(self.sim[x, x2], r) for (x2, r) in self.yr[y]]\n",
    "        k_neighbors = heapq.nlargest(self.k, neighbors, key=lambda t: t[0])\n",
    "        sum_sim = sum_ratings = actual_k = 0\n",
    "        \n",
    "        for (sim, r) in k_neighbors:\n",
    "            if sim > 0:\n",
    "                sum_sim += sim\n",
    "                sum_ratings += sim * r\n",
    "                actual_k += 1\n",
    "                \n",
    "        if actual_k < self.min_k:\n",
    "            raise PredictionImpossible('Not enough neighbors.')\n",
    "\n",
    "        est = sum_ratings / sum_sim\n",
    "        details = {'actual_k': actual_k}\n",
    "        return est, details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r'training.csv', sep='\\t')\n",
    "df_train.drop(df_train.columns[[0]], axis=1, inplace=True)\n",
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "train_ = Dataset.load_from_df(df_train[['userId', 'movieId', 'rating']], reader)\n",
    "df_test = pd.read_csv(r'testing.csv', sep='\\t')\n",
    "df_test.drop(df_test.columns[[0]], axis=1, inplace=True)\n",
    "test_ = Dataset.load_from_df(df_test[['userId', 'movieId', 'rating']], reader)\n",
    "trainset = train_.build_full_trainset()\n",
    "testset = test_.build_full_trainset().build_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "algo = MyOwnAlgorithm()\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "pd.DataFrame(predictions)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9915843601270508"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.608476161956787\n"
     ]
    }
   ],
   "source": [
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}